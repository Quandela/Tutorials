{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Remote computing on Quandela Cloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we aim at showing how to connect to Quandela Cloud services to perform computation with real QPU and simulators remotely. We are going to use a simple two modes circuit.\n",
    "\n",
    "Please note that other Cloud providers exist besides Quandela, see [providers](https://perceval.quandela.net/docs/providers.html) for additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import perceval as pcvl\n",
    "from perceval.algorithm import Sampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, define your Perceval objects (circuit, input state, etc.) as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_state = pcvl.BasicState([1, 1])\n",
    "\n",
    "c = pcvl.Circuit(2)\n",
    "c.add(0, pcvl.BS())\n",
    "c.add(0, pcvl.PS(phi = math.pi/4))\n",
    "c.add(0, pcvl.BS())\n",
    "\n",
    "pcvl.pdisplay(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, visit [cloud.quandela.com](https://cloud.quandela.com) and login to see which QPU and simulators are available, as well as their specifications. \n",
    "You have to create a token that will let you use our cloud. You can save it once and for all in Perceval (you can even do it with a terminal). \n",
    "If your token changes, just call the same method again with the new token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your token into Perceval persistent data, you only need to do it once\n",
    "pcvl.save_token('YOUR_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have chosen the platform you want your code executed on, all you have to do is to copy its name and define a `RemoteProcessor` with it. Don't forget to give the platform access rights to your token. Note that simulator platform start with \"sim:\" and actual QPUs start with \"qpu:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_simulator = pcvl.RemoteProcessor(\"sim:ascella\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can now access to the specifications of the platform directly in Perceval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = remote_simulator.specs\n",
    "pcvl.pdisplay(specs[\"specific_circuit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Platform constraints:\")\n",
    "pprint(specs[\"constraints\"])\n",
    "print(\"\\nPlatform supported parameters:\")\n",
    "pprint(specs[\"parameters\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we can specify parameters in order to tune our computation. For specific parameters, we have to use a special `set_parameter` function (or `set_parameters`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_simulator.set_circuit(c)\n",
    "remote_simulator.with_input(input_state)\n",
    "\n",
    "remote_simulator.set_parameters({  # Noisy source parameters\n",
    "    \"HOM\": .95,\n",
    "    \"transmittance\": .1,\n",
    "    \"g2\": .01\n",
    "})\n",
    "remote_simulator.min_detected_photons_filter(1)  # Output state filering on the basis of detected photons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now use the `Sampler` with our `RemoteProcessor`. You have to set a maximum shots threshold (`max_shots_per_call` named parameter) when creating a `Sampler` with a remote platform. Local simulations do not require this threshold.\n",
    "A shot is any detected event containing at least one photon, it is easy to explain, easy to measure. This shot threshold will prevent the user from consuming too many QPU resources, as once it's reached, the acquisition stops. Shots up to this threshold can be reached for all jobs generated by `Sampler` calls (e.g. calling `sample_count` thrice can lead to the use of at most `3*max_shots_per_call` shots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 200000\n",
    "sampler = Sampler(remote_simulator, max_shots_per_call=nsamples)  # You have to set a 'max_shots_per_call' named parameter\n",
    "# Here, with `min_detected_photons_filter` set to 1, all shots are de facto samples of interest.\n",
    "# Thus, in this particular case, the expected sample number can be used as the shots threshold.\n",
    "\n",
    "sampler.default_job_name = \"My sampling job\"  # All jobs created by this sampler instance will have this custom name on the cloud\n",
    "\n",
    "remote_job = sampler.sample_count.execute_async(nsamples)  # Create a job\n",
    "print(remote_job.id)  # Once created, the job was assigned a unique id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The request has now been sent to a remote platform through the cloud. As it is an asynchronous computation (`execute_async`), other computations can be performed locally before the results are retrieved. In this example, let's just wait for the end of the computation. If you go to the Quandela Cloud website again, you can see the job and its completion status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_prog = 0\n",
    "with tqdm(total=1, bar_format='{desc}{percentage:3.0f}%|{bar}|') as tq:\n",
    "    tq.set_description(f'Get {nsamples} samples from {remote_simulator.name}')\n",
    "    while not remote_job.is_complete:\n",
    "        tq.update(remote_job.status.progress/100-previous_prog)\n",
    "        previous_prog = remote_job.status.progress/100\n",
    "        time.sleep(1)\n",
    "    tq.update(1-previous_prog)\n",
    "    tq.close()\n",
    "\n",
    "print(f\"Job status = {remote_job.status()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once the previous cell has run to the end, the job is finished (again, you can see its status on the website). Let's retrieve the results to do some computation. In this case, the computation is expected to be fast (unless the simulator is unavailable or there are a lot of jobs queued), so we can use the `remote_job` object we created previously. If the computation lasted for a long time, we could have shut down our computer, then turn it back on and finally created a new job object by directly retrieving the results. The *job id* which is visible on the website, is required to resume a job and load its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' # To retrieve your job using a job id\n",
    "remote_processor = pcvl.RemoteProcessor(\"sim:ascella\", token_qcloud)\n",
    "async_job = remote_processor.resume_job(id)\n",
    "'''\n",
    "\n",
    "results = remote_job.get_results()\n",
    "print(results['results'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can run the same sampling on the corresponding QPU. In order to manage your QPU credits, you can estimate the number of shots you'd need for a particular data acquisition. Please note that the maximum shots and maximum samples number act as a dual threshold system. As soon as one of these thresholds is exceeded, the acquisition stops and the results are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpu_platform_name = \"qpu:ascella\"\n",
    "nsamples = 200000\n",
    "\n",
    "remote_qpu = pcvl.RemoteProcessor(qpu_platform_name)\n",
    "remote_qpu.set_circuit(c)\n",
    "remote_qpu.with_input(input_state)\n",
    "\n",
    "print(\"With this setup:\")\n",
    "remote_qpu.min_detected_photons_filter(2)\n",
    "required_shots = remote_qpu.estimate_required_shots(nsamples=nsamples)\n",
    "print(f\"To gather {nsamples} 2-photon coincidences on {qpu_platform_name}, you would need around {required_shots} shots.\")\n",
    "\n",
    "remote_qpu.min_detected_photons_filter(1)\n",
    "required_shots = remote_qpu.estimate_required_shots(nsamples=nsamples)\n",
    "print(f\"To gather {nsamples} photon events (with at least 1 photon) on {qpu_platform_name}, you would need exactly {required_shots} shots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_on_qpu = Sampler(remote_qpu, max_shots_per_call=nsamples)\n",
    "\n",
    "remote_job = sampler_on_qpu.sample_count\n",
    "remote_job.name = \"QPU sampling\"  # You may also specify a name to individual jobs\n",
    "remote_job.execute_async(nsamples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_prog = 0\n",
    "with tqdm(total=1, bar_format='{desc}{percentage:3.0f}%|{bar}|') as tq:\n",
    "    tq.set_description(f'Get {nsamples} samples from {remote_qpu.name}')\n",
    "    while not remote_job.is_complete:\n",
    "        tq.update(remote_job.status.progress/100-previous_prog)\n",
    "        previous_prog = remote_job.status.progress/100\n",
    "        time.sleep(1)\n",
    "    tq.update(1-previous_prog)\n",
    "    tq.close()\n",
    "\n",
    "print(f\"Job status = {remote_job.status()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = remote_job.get_results()\n",
    "print(results['results'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
