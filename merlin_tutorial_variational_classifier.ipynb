{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2f585ef9",
      "metadata": {
        "id": "2f585ef9"
      },
      "source": [
        "# First Quantum Layers: Classifying Iris with MerLin\n",
        "\n",
        "This pedagogical notebook walks through three complementary ways to instantiate and train `QuantumLayer` objects on the Iris classification task.\n",
        "\n",
        "Learning objectives\n",
        "\n",
        "- See three construction styles: a quick factory, the high-level `CircuitBuilder`, and a hand-crafted `perceval.Circuit`.\n",
        "- Understand encoding choices (angle vs amplitude), measurement strategies, and computation spaces.\n",
        "- Learn how to reduce the high-dimensional Fock outputs to classical features using grouping modules such as `LexGrouping` and `ModGrouping`.\n",
        "\n",
        "Notes\n",
        "\n",
        "- This notebook is intentionally compact: each example reuses the same dataset and optimisation loop so you can focus on circuit design differences.\n",
        "- If you are new to photonic simulation, review the \"Basic Concepts\" section in the docs for background on modes, photons and components."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "134fcc8e",
      "metadata": {
        "id": "134fcc8e"
      },
      "source": [
        "We will reuse a common data pipeline and optimisation loop while switching between three APIs:\n",
        "\n",
        "1. `QuantumLayer.simple` — a quick factory that builds a ready-to-train 10-mode / 5-photon circuit.\n",
        "2. Declarative `CircuitBuilder` — a fluent, repeatable way to assemble encoders, entangling blocks and superpositions.\n",
        "3. A fully manual `perceval.Circuit` — for maximum control when you need custom detector or experimental behaviour.\n",
        "\n",
        "Along the way we emphasise the choices that impact training and runtime: encoding (angle vs amplitude), measurement strategy (probabilities / mode expectations / amplitudes), and computation space (FOCK / UNBUNCHED / DUAL_RAIL)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, download MerLin 0.2.2\n",
        "# you may have to restart your session\n",
        "!pip install merlinquantum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiLdGZrUCjuy",
        "outputId": "8e8a8d7b-ae22-4a03-8474-227ed65580aa"
      },
      "id": "yiLdGZrUCjuy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: merlinquantum in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from merlinquantum) (2.8.0+cu126)\n",
            "Requirement already satisfied: perceval-quandela>=0.13.1 in /usr/local/lib/python3.12/dist-packages (from merlinquantum) (1.0.1)\n",
            "Requirement already satisfied: numpy>=2.2.6 in /usr/local/lib/python3.12/dist-packages (from merlinquantum) (2.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from merlinquantum) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.7.2 in /usr/local/lib/python3.12/dist-packages (from merlinquantum) (1.7.2)\n",
            "Requirement already satisfied: sympy~=1.12 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (1.13.3)\n",
            "Requirement already satisfied: scipy~=1.13 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (1.16.3)\n",
            "Requirement already satisfied: tabulate~=0.9 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (0.9.0)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (3.10.0)\n",
            "Requirement already satisfied: exqalibur~=1.0.0 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (1.0.0)\n",
            "Requirement already satisfied: multipledispatch<2 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (5.29.5)\n",
            "Requirement already satisfied: drawsvg>=2.0 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (2.4.0)\n",
            "Requirement already satisfied: requests<3 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (2.32.4)\n",
            "Requirement already satisfied: networkx<4,>=3.1 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (3.5)\n",
            "Requirement already satisfied: latexcodec<4 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (3.0.1)\n",
            "Requirement already satisfied: platformdirs<5 in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (4.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from perceval-quandela>=0.13.1->merlinquantum) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.7.2->merlinquantum) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.7.2->merlinquantum) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (75.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->merlinquantum) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->merlinquantum) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->merlinquantum) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->merlinquantum) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->perceval-quandela>=0.13.1->merlinquantum) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->perceval-quandela>=0.13.1->merlinquantum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->perceval-quandela>=0.13.1->merlinquantum) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->perceval-quandela>=0.13.1->merlinquantum) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->perceval-quandela>=0.13.1->merlinquantum) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->perceval-quandela>=0.13.1->merlinquantum) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->perceval-quandela>=0.13.1->merlinquantum) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->merlinquantum) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3->perceval-quandela>=0.13.1->merlinquantum) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3->perceval-quandela>=0.13.1->merlinquantum) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3->perceval-quandela>=0.13.1->merlinquantum) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3->perceval-quandela>=0.13.1->merlinquantum) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy~=1.12->perceval-quandela>=0.13.1->merlinquantum) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->merlinquantum) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5016e4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5016e4d",
        "outputId": "4c31acef-05c2-4131-bfb6-75229c90d885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 112 samples\n",
            "Test size: 38 samples\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import perceval as pcvl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from merlin import LexGrouping, QuantumLayer, MeasurementStrategy, ComputationSpace\n",
        "from merlin.builder import CircuitBuilder\n",
        "import perceval as pcvl\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data.astype(\"float32\")\n",
        "y = iris.target.astype(\"int64\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.25,\n",
        "    stratify=y,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "mean = X_train.mean(dim=0, keepdim=True)\n",
        "std = X_train.std(dim=0, keepdim=True).clamp_min(1e-6)\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std\n",
        "\n",
        "print(f\"Train size: {X_train.shape[0]} samples\")\n",
        "print(f\"Test size: {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea1972d2",
      "metadata": {
        "id": "ea1972d2"
      },
      "outputs": [],
      "source": [
        "# here is a function to run an experiment : train and evaluate a QuantumLayer\n",
        "\n",
        "\n",
        "def run_experiment(layer: torch.nn.Module, epochs: int = 60, lr: float = 0.05):\n",
        "    optimizer = torch.optim.Adam(layer.parameters(), lr=lr)\n",
        "    losses = []\n",
        "    for _ in range(epochs):\n",
        "        layer.train()\n",
        "        optimizer.zero_grad()\n",
        "        logits = layer(X_train)\n",
        "        loss = F.cross_entropy(logits, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    layer.eval()\n",
        "    with torch.no_grad():\n",
        "        train_preds = layer(X_train).argmax(dim=1)\n",
        "        test_preds = layer(X_test).argmax(dim=1)\n",
        "        train_acc = (train_preds == y_train).float().mean().item()\n",
        "        test_acc = (test_preds == y_test).float().mean().item()\n",
        "    return losses, train_acc, test_acc\n",
        "\n",
        "\n",
        "def describe(name: str, losses, train_acc: float, test_acc: float):\n",
        "    print(name)\n",
        "    print(f\"  epochs: {len(losses)}\")\n",
        "    print(f\"  final loss: {losses[-1]:.4f}\")\n",
        "    print(f\"  train accuracy: {train_acc:.3f}\")\n",
        "    print(f\"  test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7b72ea1",
      "metadata": {
        "id": "a7b72ea1"
      },
      "source": [
        "## 1. Quickstart factory: `QuantumLayer.simple`\n",
        "\n",
        "The `simple` factory constructs a compact, ready-to-train photonic layer (default: 10 modes, 5 photons). Use it when you want a sensible default architecture to prototype quickly. The helper:\n",
        "\n",
        "- creates an entangling interferometer, an input angle-encoding stage, optional trainable MZI blocks, and final superpositions;\n",
        "- exposes a predictable number of trainable parameters so you can compare capacities;\n",
        "- returns a PyTorch `nn.Module` you can plug into standard training loops.\n",
        "\n",
        "We use `LexGrouping` after the quantum core to collapse the Fock distribution into a small number of classical features suitable for a linear classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f402df2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f402df2",
        "outputId": "bfde3427-2e00-4045-a4d0-688abd2087fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QuantumLayer.simple\n",
            "  epochs: 80\n",
            "  final loss: 0.7972\n",
            "  train accuracy: 0.884\n",
            "  test accuracy: 0.842\n",
            "  trainable parameters: 100\n"
          ]
        }
      ],
      "source": [
        "base_simple = QuantumLayer.simple(\n",
        "    input_size=X_train.shape[1],\n",
        "    n_params=100,\n",
        "    dtype=X_train.dtype,\n",
        ")\n",
        "\n",
        "simple_layer = nn.Sequential(\n",
        "    base_simple,\n",
        "    LexGrouping(base_simple.output_size, 3),\n",
        ")\n",
        "\n",
        "losses, train_acc, test_acc = run_experiment(simple_layer, epochs=80, lr=0.01)\n",
        "trainable = sum(p.numel() for p in simple_layer.parameters() if p.requires_grad)\n",
        "describe(\"QuantumLayer.simple\", losses, train_acc, test_acc)\n",
        "print(\n",
        "    f\"  trainable parameters: {trainable}\"\n",
        ")  # this will also print the number of trainable parameters in the last Linear layer\n",
        "\n",
        "# this circuit does not work well on this dataset, let us try another circuit !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da3a7fad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "da3a7fad",
        "outputId": "bf7895d4-a88b-480b-f684-84ca80466a42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<drawsvg.drawing.Drawing at 0x7de30468fda0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     width=\"1700.0\" height=\"656.25\" viewBox=\"-30.0 0 1360.0 525.0\">\n<defs>\n</defs>\n<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,475.0 L25,475.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M25,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,425 L125,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,475 L125,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M27.5,2.5 L122.5,2.5 L122.5,497.5 L27.5,497.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"35\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=input1</text>\n<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=input2</text>\n<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=input3</text>\n<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=input4</text>\n<path d=\"M175,25 L275,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M175,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M177.5,2.5 L272.5,2.5 L272.5,97.5 L177.5,97.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"185\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M175,125.0 L275,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M275,75 L375,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M275,125 L375,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M277.5,52.5 L372.5,52.5 L372.5,147.5 L277.5,147.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"285\" y=\"66\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M175,175.0 L375,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M377.5,102.5 L472.5,102.5 L472.5,197.5 L377.5,197.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"385\" y=\"116\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M125,225.0 L475,225.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M475,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M475,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M477.5,152.5 L572.5,152.5 L572.5,247.5 L477.5,247.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"485\" y=\"166\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M125,275.0 L575,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M575,225 L675,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M575,275 L675,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M577.5,202.5 L672.5,202.5 L672.5,297.5 L577.5,297.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"585\" y=\"216\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M275,25.0 L375,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,25 L403,25 L422,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M428,44 L447,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,75 L403,75 L422,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M428,56 L447,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M400,43 L450,43 L450,57 L400,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"425\" y=\"85\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"425\" y=\"26\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M400,43 L450,43 L450,47 L400,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M443,50 L453,50 L453,60 L443,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"448\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"525\" y=\"135\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M575,125 L603,125 L622,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M628,144 L647,125 L675,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M575,175 L603,175 L622,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M628,156 L647,175 L675,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M600,143 L650,143 L650,157 L600,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"625\" y=\"185\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"625\" y=\"126\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M600,143 L650,143 L650,147 L600,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M643,150 L653,150 L653,160 L643,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"648\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M675,175 L703,175 L722,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M728,194 L747,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M675,225 L703,225 L722,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M728,206 L747,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M700,193 L750,193 L750,207 L700,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"725\" y=\"235\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"725\" y=\"176\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M700,193 L750,193 L750,197 L700,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M743,200 L753,200 L753,210 L743,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"748\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M675,275.0 L775,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M775,225 L803,225 L822,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M828,244 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M775,275 L803,275 L822,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M828,256 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M800,243 L850,243 L850,257 L800,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"825\" y=\"285\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"825\" y=\"226\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M800,243 L850,243 L850,247 L800,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M843,250 L853,250 L853,260 L843,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"848\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M125,325.0 L875,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M875,275 L903,275 L922,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M928,294 L947,275 L975,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M875,325 L903,325 L922,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M928,306 L947,325 L975,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M900,293 L950,293 L950,307 L900,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"925\" y=\"335\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"925\" y=\"276\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M900,293 L950,293 L950,297 L900,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M943,300 L953,300 L953,310 L943,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"948\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M125,375.0 L975,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M975,325 L1003,325 L1022,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1028,344 L1047,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M975,375 L1003,375 L1022,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1028,356 L1047,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1000,343 L1050,343 L1050,357 L1000,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"1025\" y=\"385\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"1025\" y=\"326\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M1000,343 L1050,343 L1050,347 L1000,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M1043,350 L1053,350 L1053,360 L1043,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"1048\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M125,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"1125\" y=\"435\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M125,475.0 L1175,475.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1175,425 L1203,425 L1222,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1228,444 L1247,425 L1275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1175,475 L1203,475 L1222,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1228,456 L1247,475 L1275,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1200,443 L1250,443 L1250,457 L1200,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"1225\" y=\"485\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"1225\" y=\"426\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M1200,443 L1250,443 L1250,447 L1200,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M1243,450 L1253,450 L1253,460 L1243,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"1248\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M475,25.0 L1275,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M575,75.0 L1275,75.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M675,125.0 L1275,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M775,175.0 L1275,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M875,225.0 L1275,225.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M975,275.0 L1275,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1075,325.0 L1275,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1175,375.0 L1275,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M1275,25.0 L1290,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M1275,75.0 L1290,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M1275,125.0 L1290,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M1275,175.0 L1290,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M1275,225.0 L1290,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M1275,275.0 L1290,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M1275,325.0 L1290,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M1275,375.0 L1290,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M1275,425.0 L1290,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M1275,475.0 L1290,475.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<text x=\"1300\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n<text x=\"1300\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n<text x=\"1300\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n<text x=\"1300\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n<text x=\"1300\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n<text x=\"1300\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n<text x=\"1300\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n<text x=\"1300\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n<text x=\"1300\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n<text x=\"1300\" y=\"478.0\" font-size=\"10\" text-anchor=\"end\">9</text>\n<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n<text x=\"0\" y=\"478.0\" font-size=\"10\" text-anchor=\"start\">9</text>\n</svg>"
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# you can visualize the circuit generated by QuantumLayer.simple\n",
        "pcvl.pdisplay(base_simple.circuit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a04f401",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "5a04f401",
        "outputId": "57a11872-d37f-4587-bc78-ecf51d18adbd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "params = [90, 100, 110]\n",
        "test_accs, train_accs = [], []\n",
        "for n_params in params:\n",
        "    base_layer = QuantumLayer.simple(\n",
        "        input_size=X_train.shape[1],\n",
        "        n_params=n_params,\n",
        "        dtype=X_train.dtype,\n",
        "    )\n",
        "    simple_layer = nn.Sequential(\n",
        "        base_layer,\n",
        "        LexGrouping(base_layer.output_size, 3),\n",
        "    )\n",
        "    losses, train_acc, test_acc = run_experiment(simple_layer, epochs=80, lr=0.01)\n",
        "    test_accs.append(test_acc)\n",
        "    train_accs.append(train_acc)\n",
        "plt.plot(params, train_accs, label=\"train\")\n",
        "plt.plot(params, test_accs, label=\"test\")\n",
        "plt.xlabel(\"Number of trainable parameters\")\n",
        "plt.xticks(ticks=params, labels=[str(p) for p in params])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41fd459a",
      "metadata": {
        "id": "41fd459a"
      },
      "source": [
        "## 2. Declarative builder API\n",
        "\n",
        "`CircuitBuilder` is the recommended approach for training: it separates circuit structure from encoding metadata and emits parameter prefixes that the `QuantumLayer` consumes. Use the builder when you need repeatable, parameterised quantum feature maps:\n",
        "\n",
        "- `add_entangling_layer(trainable=True)` lets the builder allocate a dense, expressive entangling block;\n",
        "- `add_angle_encoding(...)` declares how classical features map to phase shifters (the builder records those prefixes so `QuantumLayer` can split logical inputs automatically);\n",
        "- `add_superpositions(...)` adds non-trainable mixing layers useful for redistributing encoded information.\n",
        "\n",
        "After building the core, we again apply `LexGrouping` to reduce the Fock output to a manageable number of classical features for the head classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c9efa8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01c9efa8",
        "outputId": "cf74d134-23e8-4697-bd8b-7d88d50cccf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CircuitBuilder pipeline\n",
            "  epochs: 80\n",
            "  final loss: 0.8375\n",
            "  train accuracy: 0.670\n",
            "  test accuracy: 0.605\n",
            "  trainable parameters: 36\n"
          ]
        }
      ],
      "source": [
        "builder = CircuitBuilder(n_modes=6)\n",
        "builder.add_entangling_layer(trainable=True, name=\"U1\")\n",
        "builder.add_angle_encoding(modes=list(range(X_train.shape[1])), name=\"input\")\n",
        "builder.add_rotations(trainable=True, name=\"theta\")\n",
        "builder.add_superpositions(depth=1)\n",
        "builder_core = QuantumLayer(\n",
        "    input_size=X_train.shape[1],\n",
        "    builder=builder,\n",
        "    n_photons=3,  # equivalent to input_state = [1,1,1,0,0,0]\n",
        "    dtype=X_train.dtype,\n",
        ")\n",
        "builder_layer = nn.Sequential(\n",
        "    builder_core,\n",
        "    LexGrouping(builder_core.output_size, 3),\n",
        ")\n",
        "losses, train_acc, test_acc = run_experiment(builder_layer, epochs=80, lr=0.05)\n",
        "trainable = sum(p.numel() for p in builder_layer.parameters() if p.requires_grad)\n",
        "describe(\"CircuitBuilder pipeline\", losses, train_acc, test_acc)\n",
        "print(f\"  trainable parameters: {trainable}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a99bbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "e6a99bbd",
        "outputId": "0280454b-f779-4a25-abfe-74da40b69f7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<drawsvg.drawing.Drawing at 0x7de3041a3d70>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     width=\"1008.75\" height=\"406.25\" viewBox=\"-28.5 0 807.0 325.0\">\n<defs>\n</defs>\n<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M25,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M27.5,2.5 L122.5,2.5 L122.5,297.5 L27.5,297.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"35\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=input1</text>\n<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=input2</text>\n<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=input3</text>\n<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=input4</text>\n<path d=\"M175,25 L225,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M180,40 L189,40 L203,10 L194,10 L180,40 L189,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"197\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=theta_0</text>\n<path d=\"M175,75 L225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M180,90 L189,90 L203,60 L194,60 L180,90 L189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=theta_1</text>\n<path d=\"M175,125 L225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M180,140 L189,140 L203,110 L194,110 L180,140 L189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=theta_2</text>\n<path d=\"M175,175 L225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M180,190 L189,190 L203,160 L194,160 L180,190 L189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=theta_3</text>\n<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=theta_4</text>\n<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=theta_5</text>\n<path d=\"M225,25 L253,25 L272,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M278,44 L297,25 L325,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M225,75 L253,75 L272,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M278,56 L297,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M250,43 L300,43 L300,57 L250,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"275\" y=\"85\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"275\" y=\"26\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M250,43 L300,43 L300,47 L250,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M293,50 L303,50 L303,60 L293,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"298\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M225,125.0 L325,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M325,75 L353,75 L372,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M378,94 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M325,125 L353,125 L372,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M378,106 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M350,93 L400,93 L400,107 L350,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"375\" y=\"135\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"375\" y=\"76\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M350,93 L400,93 L400,97 L350,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M393,100 L403,100 L403,110 L393,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"398\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M225,175.0 L425,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M425,125 L453,125 L472,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M478,144 L497,125 L525,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M425,175 L453,175 L472,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M478,156 L497,175 L525,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M450,143 L500,143 L500,157 L450,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"475\" y=\"185\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"475\" y=\"126\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M450,143 L500,143 L500,147 L450,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M493,150 L503,150 L503,160 L493,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"498\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M175,225.0 L525,225.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M525,175 L553,175 L572,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M578,194 L597,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M525,225 L553,225 L572,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M578,206 L597,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M550,193 L600,193 L600,207 L550,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"575\" y=\"235\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"575\" y=\"176\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M550,193 L600,193 L600,197 L550,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M593,200 L603,200 L603,210 L593,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"598\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M175,275.0 L625,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n<text x=\"675\" y=\"285\" font-size=\"7\" text-anchor=\"middle\"></text>\n<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\"></text>\n<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n<path d=\"M325,25.0 L725,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M425,75.0 L725,75.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M525,125.0 L725,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M625,175.0 L725,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M725,25.0 L740,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M725,75.0 L740,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M725,125.0 L740,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M725,175.0 L740,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M725,225.0 L740,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M725,275.0 L740,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<text x=\"750\" y=\"28.0\" font-size=\"7\" text-anchor=\"end\">0</text>\n<text x=\"750\" y=\"78.0\" font-size=\"7\" text-anchor=\"end\">1</text>\n<text x=\"750\" y=\"128.0\" font-size=\"7\" text-anchor=\"end\">2</text>\n<text x=\"750\" y=\"178.0\" font-size=\"7\" text-anchor=\"end\">3</text>\n<text x=\"750\" y=\"228.0\" font-size=\"7\" text-anchor=\"end\">4</text>\n<text x=\"750\" y=\"278.0\" font-size=\"7\" text-anchor=\"end\">5</text>\n<text x=\"0\" y=\"28.0\" font-size=\"7\" text-anchor=\"start\">0</text>\n<text x=\"0\" y=\"78.0\" font-size=\"7\" text-anchor=\"start\">1</text>\n<text x=\"0\" y=\"128.0\" font-size=\"7\" text-anchor=\"start\">2</text>\n<text x=\"0\" y=\"178.0\" font-size=\"7\" text-anchor=\"start\">3</text>\n<text x=\"0\" y=\"228.0\" font-size=\"7\" text-anchor=\"start\">4</text>\n<text x=\"0\" y=\"278.0\" font-size=\"7\" text-anchor=\"start\">5</text>\n</svg>"
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# you can observe your circuit\n",
        "pcvl.pdisplay(builder_layer[0].circuit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9810e41",
      "metadata": {
        "id": "a9810e41"
      },
      "source": [
        "### Amplitude encoding with the Builder\n",
        "\n",
        "The builder workflow can also support amplitude encoding: instead of feeding classical features that are angle-encoded into phase shifters, you provide a (normalized) complex amplitude vector that directly prepares the input superposition. Important points:\n",
        "\n",
        "- Enable amplitude encoding when constructing the layer by passing `amplitude_encoding=True` to `QuantumLayer` (you must also provide `n_photons`).\n",
        "- The effective input size depends on the chosen `computation_space` (FOCK / UNBUNCHED / DUAL_RAIL) and the circuit -- inspect `layer.input_size` or `len(layer.state_keys)` to build correctly-sized amplitude vectors.\n",
        "- Inputs may be batched: pass a tensor of shape `(B, input_size)` to evaluate many amplitude states in one call; the layer will vectorise where possible.\n",
        "\n",
        "\n",
        "Notes:\n",
        "- When using amplitude encoding you cannot mix classical `input_parameters` with the amplitude tensor (the amplitude becomes the new input state).\n",
        "- If you require dual-rail encoding, ensure the circuit has the correct mode pairing (dual-rail expects pairs of modes per logical qubit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1024b54f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1024b54f",
        "outputId": "8d7ae789-68ab-4da4-e8c7-ca1d60561572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amplitude input size: 6\n",
            "Single state shape: torch.Size([1, 6])\n",
            "Layer output shape: torch.Size([1, 6])\n",
            "Amplitude-encoded circuit\n",
            "  epochs: 120\n",
            "  final loss: 1.0069\n",
            "  train accuracy: 0.554\n",
            "  test accuracy: 0.421\n",
            "  trainable parameters: 12\n",
            "Batched output shape: torch.Size([8, 6])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# We can build a layer without explicit encoding\n",
        "builder = CircuitBuilder(n_modes=4)\n",
        "builder.add_entangling_layer(trainable=True, name=\"U1\")  # one trainable interferometer\n",
        "\n",
        "amp_layer = QuantumLayer(\n",
        "    builder=builder,\n",
        "    n_photons=2,\n",
        "    amplitude_encoding=True,\n",
        "    computation_space=ComputationSpace.UNBUNCHED,  # or UNBUNCHED / DUAL_RAIL as appropriate\n",
        "    dtype=torch.complex64,\n",
        ")\n",
        "\n",
        "# The computation space dimension equals the number of amplitudes we must provide.\n",
        "# Here, we have 4 features, but we need to pad them to match the amplitude space.\n",
        "# We provide a simple nn.Module to pad the input_state to match the amplitude space dimension.\n",
        "num_states = amp_layer.input_size\n",
        "print(\"Amplitude input size:\", num_states)\n",
        "\n",
        "class AmplitudePad(nn.Module):\n",
        "    \"\"\"Pad real features with zeros to match the amplitude space.\"\"\"\n",
        "\n",
        "    def __init__(self, target_dim: int):\n",
        "        super().__init__()\n",
        "        self.target_dim = target_dim\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.to(torch.complex64)\n",
        "        if x.shape[-1] > self.target_dim:\n",
        "            raise ValueError(\n",
        "                f\"Expected at most {self.target_dim} features, got {x.shape[-1]}\"\n",
        "            )\n",
        "        pad_width = self.target_dim - x.shape[-1]\n",
        "        if pad_width > 0:\n",
        "            padding = torch.zeros(*x.shape[:-1], pad_width, dtype=x.dtype, device=x.device)\n",
        "            padded = torch.cat([x, padding], dim=-1)\n",
        "        else:\n",
        "            padded = x\n",
        "        norms = torch.linalg.norm(padded, dim=-1, keepdim=True)\n",
        "        norms = torch.clamp(norms, min=1e-12)\n",
        "        return padded / norms\n",
        "\n",
        "amplitude_encoder = AmplitudePad(num_states)\n",
        "\n",
        "# Single example converted to amplitudes (first sample from the dataset)\n",
        "single_state = amplitude_encoder(X_train[0].unsqueeze(0))\n",
        "print(\"Single state shape:\", single_state.shape)\n",
        "\n",
        "# Single evaluation\n",
        "output = amp_layer(single_state)\n",
        "print(\"Layer output shape:\", output.shape)\n",
        "\n",
        "manual_layer = nn.Sequential(\n",
        "    amplitude_encoder,\n",
        "    amp_layer,\n",
        "    LexGrouping(amp_layer.output_size, 3),\n",
        ")\n",
        "\n",
        "losses, train_acc, test_acc = run_experiment(manual_layer, epochs=120, lr=0.05)\n",
        "\n",
        "trainable = sum(p.numel() for p in manual_layer.parameters() if p.requires_grad)\n",
        "describe(\"Amplitude-encoded circuit\", losses, train_acc, test_acc)\n",
        "print(f\"  trainable parameters: {trainable}\")\n",
        "\n",
        "# Batched evaluation: pad and normalise a batch of inputs\n",
        "batch = amplitude_encoder(X_train[:8])\n",
        "batched_out = amp_layer(batch)\n",
        "print(\"Batched output shape:\", batched_out.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba326ccd",
      "metadata": {
        "id": "ba326ccd"
      },
      "source": [
        "## 3. Hand-crafted Perceval circuit\n",
        "\n",
        "When you need full control over the optical layout or to attach detectors/noise models via `perceval.Experiment`, build the circuit manually and pass it to `QuantumLayer`. This mode is useful when:\n",
        "\n",
        "- you want custom detector models (threshold vs PNR) or realistic noise models;\n",
        "- you require special component placements that a builder cannot express;\n",
        "- you need to reuse the same `perceval.Experiment` across different training runs.\n",
        "\n",
        "Remember: amplitude outputs are only available for noiseless unitary experiments. If you attach detectors or loss models, use `MeasurementStrategy.PROBABILITIES` or `MODE_EXPECTATIONS` instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680842d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "680842d0",
        "outputId": "9138db76-bbf4-47ef-ff0c-28327621c004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Perceval circuit\n",
            "  epochs: 120\n",
            "  final loss: 0.7486\n",
            "  train accuracy: 0.946\n",
            "  test accuracy: 0.921\n",
            "  trainable parameters: 60\n"
          ]
        }
      ],
      "source": [
        "modes = 6\n",
        "# left generic interferometer\n",
        "wl = pcvl.GenericInterferometer(\n",
        "    modes,\n",
        "    lambda i: pcvl.BS()\n",
        "    // pcvl.PS(pcvl.P(f\"theta_li{i}\"))\n",
        "    // pcvl.BS()\n",
        "    // pcvl.PS(pcvl.P(f\"theta_lo{i}\")),\n",
        "    shape=pcvl.InterferometerShape.RECTANGLE,\n",
        ")\n",
        "# data encoding\n",
        "circuit = pcvl.Circuit(modes)\n",
        "circuit.add(0, wl)\n",
        "for mode in range(len(iris.feature_names)):\n",
        "    circuit.add(mode, pcvl.PS(pcvl.P(f\"input{mode}\")))\n",
        "# right generic interferometer\n",
        "wr = pcvl.GenericInterferometer(\n",
        "    modes,\n",
        "    lambda i: pcvl.BS()\n",
        "    // pcvl.PS(pcvl.P(f\"theta_ri{i}\"))\n",
        "    // pcvl.BS()\n",
        "    // pcvl.PS(pcvl.P(f\"theta_ro{i}\")),\n",
        "    shape=pcvl.InterferometerShape.RECTANGLE,\n",
        ")\n",
        "circuit.add(0, wr)\n",
        "\n",
        "manual_core = QuantumLayer(\n",
        "    input_size=X_train.shape[1],\n",
        "    circuit=circuit,\n",
        "    input_state=[\n",
        "        1,\n",
        "        0,\n",
        "        1,\n",
        "        0,\n",
        "        1,\n",
        "        0,\n",
        "    ],  # here, you can just precise the n_photons -> input_state = [1,1,1,0,0,0],\n",
        "    # you can also use pcvl.BasiscState to define more complex input states: # pcvl.BasicState([1,0,1,0,1,0])\n",
        "    trainable_parameters=[\"theta\"],\n",
        "    input_parameters=[\"input\"],\n",
        "    dtype=X_train.dtype,\n",
        ")\n",
        "\n",
        "manual_layer = nn.Sequential(\n",
        "    manual_core,\n",
        "    LexGrouping(manual_core.output_size, 3),\n",
        ")\n",
        "\n",
        "losses, train_acc, test_acc = run_experiment(manual_layer, epochs=120, lr=0.05)\n",
        "trainable = sum(p.numel() for p in manual_layer.parameters() if p.requires_grad)\n",
        "describe(\"Manual Perceval circuit\", losses, train_acc, test_acc)\n",
        "print(f\"  trainable parameters: {trainable}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5590923b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "5590923b",
        "outputId": "549676c1-3727-45e6-debb-0760a192ede8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<drawsvg.drawing.Drawing at 0x7de3041ba6c0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     width=\"446.25\" height=\"406.25\" viewBox=\"-28.5 0 357.0 325.0\">\n<defs>\n</defs>\n<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M25,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M27.5,2.5 L122.5,2.5 L122.5,297.5 L27.5,297.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"35\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=input0</text>\n<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=input1</text>\n<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=input2</text>\n<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=input3</text>\n<path d=\"M125,225.0 L175,225.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M125,275.0 L175,275.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M175,25 L275,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M175,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M175,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M175,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M175,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M175,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M177.5,2.5 L272.5,2.5 L272.5,297.5 L177.5,297.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"185\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M275,25.0 L290,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M275,75.0 L290,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M275,125.0 L290,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M275,175.0 L290,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M275,225.0 L290,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M275,275.0 L290,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<text x=\"300\" y=\"28.0\" font-size=\"7\" text-anchor=\"end\">0</text>\n<text x=\"300\" y=\"78.0\" font-size=\"7\" text-anchor=\"end\">1</text>\n<text x=\"300\" y=\"128.0\" font-size=\"7\" text-anchor=\"end\">2</text>\n<text x=\"300\" y=\"178.0\" font-size=\"7\" text-anchor=\"end\">3</text>\n<text x=\"300\" y=\"228.0\" font-size=\"7\" text-anchor=\"end\">4</text>\n<text x=\"300\" y=\"278.0\" font-size=\"7\" text-anchor=\"end\">5</text>\n<text x=\"0\" y=\"28.0\" font-size=\"7\" text-anchor=\"start\">0</text>\n<text x=\"0\" y=\"78.0\" font-size=\"7\" text-anchor=\"start\">1</text>\n<text x=\"0\" y=\"128.0\" font-size=\"7\" text-anchor=\"start\">2</text>\n<text x=\"0\" y=\"178.0\" font-size=\"7\" text-anchor=\"start\">3</text>\n<text x=\"0\" y=\"228.0\" font-size=\"7\" text-anchor=\"start\">4</text>\n<text x=\"0\" y=\"278.0\" font-size=\"7\" text-anchor=\"start\">5</text>\n</svg>"
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# display the circuit\n",
        "pcvl.pdisplay(manual_core.circuit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "454c3f01",
      "metadata": {
        "id": "454c3f01"
      },
      "source": [
        "### Experiment-backed execution: detectors, noise and supported parameters\n",
        "\n",
        "When you need to evaluate detector-level behaviour (threshold vs PNR detectors) or attach realistic noise models, wrap your `perceval.Circuit` into a `perceval.Experiment` and pass the experiment to `QuantumLayer`. The `QuantumLayer` will reuse the experiment measurement semantics (detectors, noise) and adapt available outputs accordingly.\n",
        "\n",
        "Key behaviours and supported parameters\n",
        "\n",
        "- detectors: assign per-mode detector types on the `Experiment` (e.g. `pcvl.Detector.threshold()` or `pcvl.Detector.pnr()`).\n",
        "- noise / loss: `Experiment.noise` accepts `pcvl.NoiseModel` instances to model brightness, transmittance, dark counts, etc.\n",
        "- measurement_strategy: when detectors or loss are present, amplitude outputs are not available. Use `PROBABILITIES` or `MODE_EXPECTATIONS`.\n",
        "- shots / sampling_method: configure `shots` and `sampling_method` on `QuantumLayer` to control sampling-based evaluation (e.g. stochastic multinomial sampling).\n",
        "- computation_space / no_bunching: choose `ComputationSpace` or the legacy `no_bunching` flag to control the simulated Fock basis (FOCK, UNBUNCHED/NO_BUNCHING, DUAL_RAIL).\n",
        "- device / dtype: pass `device` and `dtype` to the layer so the underlying Torch-enabled compute graph is built on the correct device and precision.\n",
        "\n",
        "Notes\n",
        "\n",
        "- The experiment becomes the single source of truth for measurement semantics; any detector or noise changes on the `Experiment` will be respected by the `QuantumLayer`.\n",
        "- Using `shots>0` returns sampled counts (stochastic). When training with gradient-based methods, sampled evaluation is typically disabled or handled with special autodiff backends; check `QuantumLayer` sampling docs for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7d6b4c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7d6b4c3",
        "outputId": "fd9e6aad-8a21-45ac-ce7b-ba833991c9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment-based layer with noise model\n",
            "  epochs: 80\n",
            "  final loss: 0.5766\n",
            "  train accuracy: 0.812\n",
            "  test accuracy: 0.816\n"
          ]
        }
      ],
      "source": [
        "# Build your perceval circuit as before\n",
        "circuit = circuit  # reuse the `circuit` variable from the previous cell\n",
        "\n",
        "# Create an Experiment that attaches noise and detectors\n",
        "experiment = pcvl.Experiment(circuit)\n",
        "experiment.noise = pcvl.NoiseModel(brightness=0.6, transmittance=0.8)\n",
        "# Example: threshold detector on mode 0, PNR on mode 1\n",
        "experiment.detectors[0] = pcvl.Detector.threshold()\n",
        "experiment.detectors[1] = pcvl.Detector.pnr()\n",
        "\n",
        "# Construct a QuantumLayer that reuses the experiment measurement semantics\n",
        "experiment_layer = QuantumLayer(\n",
        "    input_size=X_train.shape[1],\n",
        "    experiment=experiment,\n",
        "    input_state=[1, 1, 1, 0, 0, 0],\n",
        "    input_parameters=[\"input\"],\n",
        "    trainable_parameters=[\"theta\"],\n",
        "    measurement_strategy=MeasurementStrategy.PROBABILITIES,\n",
        "    computation_space=ComputationSpace.FOCK,\n",
        "    device=None,                   # or torch.device(\"cuda\") if available\n",
        "    dtype=torch.float32,\n",
        ")\n",
        "\n",
        "# Downstream grouping and training is unchanged\n",
        "model_with_noise = nn.Sequential(\n",
        "    experiment_layer,\n",
        "    LexGrouping(experiment_layer.output_size, 3),\n",
        "    nn.Linear(3, 3),\n",
        ")\n",
        "\n",
        "# Run training as before\n",
        "losses, train_acc, test_acc = run_experiment(model_with_noise, epochs=80, lr=0.05)\n",
        "describe(\"Experiment-based layer with noise model\", losses, train_acc, test_acc)\n",
        "# we can observe a lower performance due to the noise model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d43797b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "d43797b2",
        "outputId": "d346253b-f435-4ebd-f6d0-fdcfef7dba85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<drawsvg.drawing.Drawing at 0x7de30437ea80>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     width=\"258.75\" height=\"406.25\" viewBox=\"-28.5 0 207.0 325.0\">\n<defs>\n</defs>\n<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M25,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M27.5,2.5 L122.5,2.5 L122.5,297.5 L27.5,297.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"35\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n<path d=\"M125,25.0 L140,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M125,75.0 L140,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M125,125.0 L140,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M125,175.0 L140,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M125,225.0 L140,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M125,275.0 L140,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<text x=\"150\" y=\"28.0\" font-size=\"7\" text-anchor=\"end\">0</text>\n<text x=\"150\" y=\"78.0\" font-size=\"7\" text-anchor=\"end\">1</text>\n<text x=\"150\" y=\"128.0\" font-size=\"7\" text-anchor=\"end\">2</text>\n<text x=\"150\" y=\"178.0\" font-size=\"7\" text-anchor=\"end\">3</text>\n<text x=\"150\" y=\"228.0\" font-size=\"7\" text-anchor=\"end\">4</text>\n<text x=\"150\" y=\"278.0\" font-size=\"7\" text-anchor=\"end\">5</text>\n<text x=\"0\" y=\"28.0\" font-size=\"7\" text-anchor=\"start\">0</text>\n<text x=\"0\" y=\"78.0\" font-size=\"7\" text-anchor=\"start\">1</text>\n<text x=\"0\" y=\"128.0\" font-size=\"7\" text-anchor=\"start\">2</text>\n<text x=\"0\" y=\"178.0\" font-size=\"7\" text-anchor=\"start\">3</text>\n<text x=\"0\" y=\"228.0\" font-size=\"7\" text-anchor=\"start\">4</text>\n<text x=\"0\" y=\"278.0\" font-size=\"7\" text-anchor=\"start\">5</text>\n</svg>"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# you can visualize the circuit (same as before, but with noise and detectors that we cannot see here)\n",
        "pcvl.pdisplay(experiment_layer.circuit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21171a60",
      "metadata": {
        "id": "21171a60"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook we explored three practical ways to build and train photonic QuantumLayer modules:\n",
        "\n",
        "- QuantumLayer.simple: a compact, ready-to-train factory useful for fast prototyping and capacity comparisons.\n",
        "- CircuitBuilder: a declarative and repeatable API that separates encoding metadata from circuit structure and is the recommended path for training experiments.\n",
        "- Hand-crafted Perceval circuits & Experiment: full control over optical layout, detectors and noise models; use this when you need detector-level semantics or to evaluate realistic experiment conditions.\n",
        "\n",
        "Key takeaways:\n",
        "\n",
        "- Choose your measurement strategy to match the downstream head (probabilities for dense heads, mode expectations to reduce parameters, amplitudes only for noiseless unitary simulations).\n",
        "- Grouping (LexGrouping / ModGrouping) is an effective way to collapse the combinatorial Fock outputs into a compact classical representation.\n",
        "- The computation space (FOCK / UNBUNCHED / DUAL_RAIL) controls the simulator's state basis and strongly impacts runtime and memory; prefer UNBUNCHED (no-bunching) when your circuits restrict photons to distinct modes.\n",
        "- Amplitude encoding requires the full computation-space vector; pad missing amplitudes with zeros and re-normalise before passing data to the layer.\n",
        "- When using experiments with detectors or noise, switch to sampling/probability outputs and consider shot noise when training or benchmarking.\n",
        "\n",
        "Next steps and resources:\n",
        "\n",
        "- Explore amplitude vs angle encoders and record how zero-padded amplitude normalisation influences optimisation.\n",
        "- Benchmark computation spaces on your circuits to choose the best trade-off between accuracy and performance.\n",
        "- Consult the documentation pages referenced in the notebook for deeper guidance on encoding, grouping and measurement strategies.\n",
        "\n",
        "Happy prototyping — feel free to copy cells from this notebook into your own experiments and extend the examples to larger datasets or different circuit topologies."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "merlin-pip",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}